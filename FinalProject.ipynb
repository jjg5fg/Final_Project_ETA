{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979923b5-0493-4768-ad1a-06db54f0bc7a",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "\n",
    "DS 5001 Exploratory Text Analytics | Spring 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046f57f-12ed-4259-be3d-60cb67b8d044",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "- Full Name: John Gallagher\n",
    "- Userid: jjg5fg\n",
    "- GitHub Repo URL: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- UVA Box URL: https://virginia.box.com/s/mm98m5lh0iadess09hiyr7s5m3vd3fk0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57acd11d-eb04-4bcc-b115-f205f367de49",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of the final project is for you to create a **digital analytical edition** of a corpus using the tools, practices, and perspectives youâ€™ve learning in this course. You will select a corpus that has already been digitized and transcribed, parse that into an F-compliant set of tables, and then generate and visualize the results of a series of fitted models. You will also draw some tentative conclusions regarding the linguistic, cultural, psychological, or historical features represented by your corpus. The point of the exercise is to have you work with a corpus through the entire pipeline from ingestion to interpretation. \n",
    "\n",
    "Specifically, you will acquire a collection of long-form texts and perform the following operations:\n",
    "\n",
    "- **Convert** the collection from their source formats (F0) into a set of tables that conform to the Standard Text Analytic Data Model (F2).\n",
    "- **Annotate** these tables with statistical and linguistic features using NLP libraries such as NLTK (F3).\n",
    "- **Produce** a vector representation of the corpus to generate TFIDF values to add to the TOKEN (aka CORPUS) and VOCAB tables (F4).\n",
    "- **Model** the annotated and vectorized model with tables and features derived from the application of unsupervised methods, including PCA, LDA, and word2vec (F5).\n",
    "- **Explore** your results using statistical and visual methods.\n",
    "- **Present** conclusions about patterns observed in the corpus by means of these operations.\n",
    "\n",
    "When you are finished, you will make the results of your work available in GitHub (for code) and UVA Box (for data). You will submit to Gradescope (via Canvas) a PDF version of a Jupyter notebook that contains the information listed below.\n",
    "\n",
    "# Some Details\n",
    "\n",
    "- Please fill out your answers in each task below by editing the markdown cell. \n",
    "- Replace text that asks you to insert something with the thing, i.e. replace `(INSERT IMAGE HERE)` with an image element, e.g. `![](image.png)`.\n",
    "- For URLs, just paste the raw URL directly into the text area. Don't worry about providing link labels using `[label](link)`.\n",
    "- Please do not alter the structure of the document or cell, i.e. the bulleted lists. \n",
    "- You may add explanatory paragraphs below the bulleted lists.\n",
    "- Please name your tables as they are named in each task below.\n",
    "- Tasks are indicated by headers with point values in parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b6d68-e039-4612-858b-29510eeb5365",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0889de-cd53-4aa5-80b2-a2a39060776a",
   "metadata": {},
   "source": [
    "## Source Description (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e395a-4b0b-4ba3-9112-80c733998dbe",
   "metadata": {},
   "source": [
    "Provide a brief description of your source material, including its provenance and content. Tell us where you found it and what kind of content it contains.\n",
    "\n",
    "The source material is a collection of US Presidential speeches up until September 25th 2019. This data is from [Kaggle](https://www.kaggle.com/datasets/littleotter/united-states-presidential-speeches) and collected from the UVA Miller Center. The dataset contains a corpus of all speeches and then broken up by US presidential eras. The corpus of all speeches is going to be used for project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b507c1-6dc2-44f7-b74c-790d84a48e8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Features (1)\n",
    "\n",
    "Add values for the following items. (Do this for all following bulleted lists.)\n",
    "\n",
    "- Source URL: https://www.kaggle.com/datasets/littleotter/united-states-presidential-speeches\n",
    "- UVA Box URL: https://virginia.app.box.com/folder/256969523790\n",
    "- Number of raw documents: roughly 1000 speeches\n",
    "- Total size of raw documents (e.g. in MB): 22 MB\n",
    "- File format(s), e.g. XML, plaintext, etc.: csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e81b1-9f70-47b5-bb25-49be4e76b98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Source Document Structure (1)\n",
    "\n",
    "Provide a brief description of the internal structure of each document. That, describe the typical elements found in document and their relation to each other. For example, a corpus of letters might be described as having a date, an addressee, a salutation, a set of content paragraphs, and closing. If they are various structures, state that.\n",
    "\n",
    "The data is a CSV with the following columns, 'date', 'president', 'party', 'speech title','summary', 'transcript' and 'url'. The main column of interest is 'transcript' as that is the text of the speech. Speeches vary in length but follow similiar format of addressing a group, The other columns will be used for riffs at the end of the notebook and placed in a LIB table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4c9f-e101-46fe-ac59-a35a1b148a4b",
   "metadata": {},
   "source": [
    "# Parsed and Annotated Data\n",
    "\n",
    "Parse the raw data into the three core tables of your addition: the `LIB`, `CORPUS`, and `VOCAB` tables.\n",
    "\n",
    "These tables will be stored as CSV files with header rows.\n",
    "\n",
    "You may consider using `|` as a delimitter.\n",
    "\n",
    "Provide the following information for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d05ce4-ac5c-43ea-a07b-c4626338f80e",
   "metadata": {},
   "source": [
    "## LIB (2)\n",
    "\n",
    "The source documents the corpus comprises. These may be books, plays, newspaper articles, abstracts, blog posts, etc. \n",
    "\n",
    "Note that these are *not* documents in the sense used to describe a bag-of-words representation of a text, e.g. chapter.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/no2s3onves8lwksx1t9zhwub6k317o3x\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Number of observations: 991 speeches\n",
    "- List of features, including at least three that may be used for model summarization (e.g. date, author, etc.): Date, President, Party\n",
    "- Average length of each document in characters: 22523"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304204a5-00be-46ad-b98b-0d10a9c8ca4b",
   "metadata": {},
   "source": [
    "## CORPUS (2)\n",
    "\n",
    "The sequence of word tokens in the corpus, indexed by their location in the corpus and document structures.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/lhftw0mk3cgf0iex8kaw5l08wmv2jdqm\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Number of observations Between (should be >= 500,000 and <= 2,000,000 observations.): Roughly 3.8 million obervations (3838307)\n",
    "- OHCO Structure (as delimitted column names): speech, sentence, token\n",
    "- Columns (as delimitted column names, including `token_str`, `term_str`, `pos`, and `pos_group`): `speech_id`, `sent_num`, `token_num`, `pos_tuple`, `pos`, `token_str`, `term_str`, `pos_group`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3214e-e6dd-42d6-842f-555d0058986e",
   "metadata": {},
   "source": [
    "## VOCAB (2)\n",
    "\n",
    "The unique word types (terms) in the corpus.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/ojrj9ha6nbr084se2b7enog2h75p47cn\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma \n",
    "- Number of observations: 38355\n",
    "- Columns (as delimitted names, including `n`, `p`', `i`, `dfidf`, `porter_stem`, `max_pos` and `max_pos_group`, `stop`): `n`, `n_chars`, `p`,`i`, `max_pos`, `n_pos`, `cat_pos`, `stop`, `stem_porter`, `stem_snowball`, `stem_lancaster`, `dfidf`, `max_pos_group`\n",
    "- Note: Your VOCAB may contain ngrams. If so, add a feature for `ngram_length`.\n",
    "- List the top 20 significant words in the corpus by DFIDF.\n",
    "\n",
    "| term_str     | Value       |\n",
    "|--------------|-------------|\n",
    "| nearly       | 525.960837  |\n",
    "| away         | 525.960837  |\n",
    "| used         | 525.960837  |\n",
    "| though       | 525.960565  |\n",
    "| terms        | 525.960565  |\n",
    "| lead         | 525.957156  |\n",
    "| party        | 525.956330  |\n",
    "| seek         | 525.949533  |\n",
    "| held         | 525.949533  |\n",
    "| self         | 525.949533  |\n",
    "| independence | 525.949533  |\n",
    "| including    | 525.948120  |\n",
    "| experience   | 525.948120  |\n",
    "| feel         | 525.948120  |\n",
    "| forward      | 525.948120  |\n",
    "| going        | 525.948120  |\n",
    "| fair         | 525.948120  |\n",
    "| regard       | 525.948120  |\n",
    "| sure         | 525.937979  |\n",
    "| longer       | 525.937979  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dabdc-baae-4408-95bc-2f735824d59b",
   "metadata": {},
   "source": [
    "# Derived Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2ef9c-1cb5-41e8-a5ee-1e37428b4539",
   "metadata": {},
   "source": [
    "## BOW (3)\n",
    "\n",
    "A bag-of-words representation of the CORPUS.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/sbh8qj940g3g4rmv4mdrmlq621rfbjnf\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Bag (expressed in terms of OHCO levels): speeches\n",
    "- Number of observations: 941286\n",
    "- Columns (as delimitted names, including `n`, `tfidf`): `speech_id`, `term_str`, `n`, `tdidf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29890d2f-bf96-43ad-8d08-792393830163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DTM (3)\n",
    "\n",
    "A represenation of the BOW as a sparse count matrix.\n",
    "\n",
    "- UVA Box URL:https://virginia.box.com/s/2pee6qf7a1x4ytii02isldg0vd091ofs\n",
    "- UVA Box URL of BOW used to generate (if applicable): https://virginia.box.com/s/sbh8qj940g3g4rmv4mdrmlq621rfbjnf\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Bag (expressed in terms of OHCO levels): speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b4774-7c76-401d-a9de-2704f28a0821",
   "metadata": {},
   "source": [
    "## TFIDF (3)\n",
    "\n",
    "A Document-Term matrix with TFIDF values.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/tz82rm6t4kkomvtpu5hkttnyw2qjdou7\n",
    "- UVA Box URL of DTM or BOW used to create: https://virginia.box.com/s/2pee6qf7a1x4ytii02isldg0vd091ofs\n",
    "or https://virginia.box.com/s/sbh8qj940g3g4rmv4mdrmlq621rfbjnf\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Description of TFIDIF formula ($\\LaTeX$ OK):\n",
    "\n",
    "$TF_{\\text{max}}(t, d) = \\frac{f_{t,d}}{\\max_{t'}(f_{t',d})}$\n",
    "\n",
    " where $f_{t,d}$ is the frequency of term $t$ in document $d$, and $\\max_{t'}(f_{t',d})$ is the maximum frequency of any term in document $d$\n",
    "\n",
    "$IDF_{\\text{standard}}(t) = \\log_2\\left(\\frac{N}{DF_t}\\right)$\n",
    "\n",
    "where $N$ is the total number of documents, and $DF_t$ is the number of documents that contain the term \n",
    "$t$.\n",
    "\n",
    "$TFIDF_{t, d} = TF_{\\text{max}}(t, d) \\times IDF_{\\text{standard}}(t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34f5ca-5361-4701-b9dd-9da66859b40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced and Normalized TFIDF_L2 (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c548dd2-f692-4365-936c-39c84df79b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "A Document-Term matrix with L2 normalized TFIDF values.\n",
    "\n",
    "- UVA Box URL:  https://virginia.box.com/s/1bkm283d6ven6u2m1tgiyuqucqafj48s\n",
    "- UVA Box URL of source TFIDF table: https://virginia.box.com/s/tz82rm6t4kkomvtpu5hkttnyw2qjdou7\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter:comma\n",
    "- Number of features (i.e. significant words): 5000 words\n",
    "- Principle of significant word selection: NN, VB, JJ and not NNP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50da94-af36-4e8d-b1a7-24dbcf431880",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df79264-dd93-4199-be38-db31579b7ce8",
   "metadata": {},
   "source": [
    "## PCA Components (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/ty31x7g52s8g137mw7d7zd0aegs4bjs3\n",
    "- UVA Box URL of the source TFIDF_L2 table: https://virginia.box.com/s/1bkm283d6ven6u2m1tgiyuqucqafj48s\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Number of components: 10\n",
    "- Library used to generate: Sklearn\n",
    "- Top 5 positive terms for first component: ['treaty', 'subject', 'revenue', 'commerce', 'public']\n",
    "- Top 5 negative terms for second component: ['proclamation', 'aforesaid', 'whereof', 'seal', 'thereof']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adc882-cbce-4d24-9923-5d36ac609f43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA DCM (4)\n",
    "\n",
    "The document-component matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/1utgwmtk2bsbo93v17pm6aubzqf3ukv3\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd2a4a-7f2f-4259-a5c4-063168cb1b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA Loadings (4)\n",
    "\n",
    "The component-term matrix generated.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/39x643w2staybdotf12yhml44ghhfu0f\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fff42f-6665-4941-ba3d-034627dc0124",
   "metadata": {},
   "source": [
    "## PCA Visualization 1 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the first two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "\n",
    "![PCA of Components 0 and 1](pca_0_1.png)\n",
    "\n",
    "\n",
    "![PCA of Components 0 and 1](loadings_0_1.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the first component:\n",
    "\n",
    "PCA: PC0 shows separation between the political parties, with republican having positive PC0 values showing distinct characteristics. Older parties, have more negative PC0 values indicating they are different compared to present day parties.  Republicans have wider range in box plot showing more variability compared to other parties. \n",
    "\n",
    "Loadings: The loadings show that most speeches have similar patterns in their usage of words, as indicated by the clustering around the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb54565-7669-4a2f-90b2-a4c283277c02",
   "metadata": {},
   "source": [
    "## PCA Visualization 2 (4)\n",
    "\n",
    "Include a scatterplot of documents in the space created by the second two components.\n",
    "\n",
    "Color the points based on a metadata feature associated with the documents.\n",
    "\n",
    "Also include a scatterplot of the loadings for the same two components. (This does not need a feature mapped onto color.)\n",
    "![PCA 1 and 2](pca_1_2.png)\n",
    "\n",
    "![PCA Loadings 1 and 2](loadings_1_2.png)\n",
    "\n",
    "Briefly describe the nature of the polarity you see in the second component:\n",
    "\n",
    "PCA: The scatter plot shows a clear distribution of speeches along the PC1 axis by political party. Similar to above, Republicans have positive PC1 values and older parties cluster among negative values. However, the distinction is not as obvious as first one.\n",
    "\n",
    "Loadings: Similar to first one, centered along the origin, however, there are more outliers, suggesting those speeches contain unique features that differentiate them from the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee23b2-25d1-4226-bf31-1607e5ed4677",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA TOPIC (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/6ohfxeiw8u4o0cv07q4p75yoe5xag8ga\n",
    "- UVA Box URL of count matrix used to create: https://virginia.box.com/s/i4oj9gmokqat2tipl6urze7bng0j3kdh\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Libary used to compute: sklearn\n",
    "- A description of any filtering, e.g. POS (Nouns and Verbs only): Same as earlier, NN, VB, JJ and not NNP\n",
    "- Number of components: 2\n",
    "- Any other parameters used: \n",
    "ngram_range = (1, 2)\n",
    "n_terms = 4000\n",
    "n_topics = 40\n",
    "max_iter = 20\n",
    "n_top_terms = 9\n",
    "- Top 5 words and best-guess labels for topic five topics by mean document weight:\n",
    "  - T06:  years life home efforts children danger  4478.998558 Post tragedy speech\n",
    "  - T16: country peace security prosperity energy  4337.812354 State of the Union\n",
    "  - T04 year way increase expenditures revenue 4225.641413 Finance Related\n",
    "  - T10: citizens state territory claims convention 4126.661523 Convention Talk\n",
    "  - T39: tax capital banks taxes rates 4010.247723 Tax Bills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518d520-4a5c-48fa-836d-f8ea3e3c2f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA THETA (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/w2n6g33m24tba7j74vop47h147bpw37x\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8808b30-64f4-4249-95d5-d7c0925ce432",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA PHI (4)\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/bz52bzt6r6u1g7jfkus864tasorczwkh\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e404bf-8a2a-4eb4-ba89-0c708c8f359d",
   "metadata": {},
   "source": [
    "## LDA + PCA Visualization (4)\n",
    "\n",
    "Apply PCA to the PHI table and plot the topics in the space opened by the first two components.\n",
    "\n",
    "Size the points based on the mean document weight of each topic (using the THETA table).\n",
    "\n",
    "Color the points basd on a metadata feature from the LIB table.\n",
    "\n",
    "Provide a brief interpretation of what you see.\n",
    "\n",
    "![PHI PCA ](plot_lda_pca.png)\n",
    "\n",
    "From the LIB table, the president with highest score for the topic was plotted. \n",
    "\n",
    "Famous presidents like Teddy Roosevelt and John F Kennedy are alone. A lot of the \"founding fathers\" James Madison, Thomas Jefferson were lumped together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1f327-a386-476a-8d94-2ab7a63afa7a",
   "metadata": {},
   "source": [
    "## Sentiment VOCAB_SENT (4)\n",
    "\n",
    "Sentiment values associated with a subset of the VOCAB from a curated sentiment lexicon.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/2axozbyz3gnc6py59s4ogswxjq03himc\n",
    "- UVA Box URL for source lexicon: https://virginia.box.com/s/j8jxbzq61apqnqr9qo3xim5krvfrutg5\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a9d67-1560-4be9-b82a-b99a60b5c93e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment BOW_SENT (4)\n",
    "\n",
    "Sentiment values from VOCAB_SENT mapped onto BOW.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/9cop60xkz96rti1jztjbi455t61ecapa\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee6837-b12e-453d-96c1-59eaa4b28883",
   "metadata": {},
   "source": [
    "## Sentiment DOC_SENT (4)\n",
    "\n",
    "Computed sentiment per bag computed from BOW_SENT.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/cthmexq7d7kh9mthzw3qh44w05kkbjec\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Document bag expressed in terms of OHCO levels: speech_level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cba13-e60a-4940-a06d-02479f002c3c",
   "metadata": {},
   "source": [
    "## Sentiment Plot (4)\n",
    "\n",
    "Plot sentiment over some metric space, such as time.\n",
    "\n",
    "If you don't have a metric metadata features, plot sentiment over a feature of your choice.\n",
    "\n",
    "You may use a bar chart or a line graph.\n",
    "\n",
    "![decades](Sent_decade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d2316-317b-4d95-a804-aff98242e411",
   "metadata": {},
   "source": [
    "## VOCAB_W2V (4)\n",
    "\n",
    "A table of word2vec features associated with terms in the VOCAB table.\n",
    "\n",
    "- UVA Box URL: https://virginia.box.com/s/0twrvum5a2srsmh5c85ai36ljfiy0mm3\n",
    "- GitHub URL for notebook used to create: https://github.com/jjg5fg/Final_Project_ETA\n",
    "- Delimitter: comma\n",
    "- Document bag expressed in terms of OHCO levels: speech_id\n",
    "- Number of features generated: vector size 246\n",
    "- The library used to generate the embeddings: gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c1974-047b-4285-9f4d-7f3314f39542",
   "metadata": {},
   "source": [
    "## Word2vec tSNE Plot (4)\n",
    "\n",
    "Plot word embedding featues in two-dimensions using t-SNE.\n",
    "\n",
    "Describe a cluster in the plot that captures your attention.\n",
    "\n",
    "![TSNE_plot](tsne_plot.png)\n",
    "\n",
    "\n",
    "![TSNE_cluster_plot](tsne_zoomed_in.png)\n",
    "\n",
    "\n",
    "The cluster that got was big orange dot beloved, and the words around make logical sense, dedication, belief, founders. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75878341-7fe8-4e22-b908-36029f9818e8",
   "metadata": {},
   "source": [
    "# Riffs\n",
    "\n",
    "Provde at least three visualizations that combine the preceding model data in interesting ways.\n",
    "\n",
    "These should provide insight into how features in the LIB table are related. \n",
    "\n",
    "The nature of this relationship is left open to you -- it may be correlation, or mutual information, or something less well defined. \n",
    "\n",
    "In doing so, consider the following visualization types:\n",
    "\n",
    "- Hierarchical cluster diagrams\n",
    "- Heatmaps\n",
    "- Scatter plots\n",
    "- KDE plots\n",
    "- Dispersion plots\n",
    "- t-SNE plots\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62acf1-6bb0-45d0-aed2-863b285f8cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 1 (5)\n",
    "\n",
    "![RIFF_1](RIFF_1.png)\n",
    "\n",
    "The first RIFF was plotting key US talking points per decade. These words include economy, education, freedom, health and war. War dominated over the entirety of the corpus, until 2000s, with spikes coming during predictable times, like Civil War, World Wars and Cold War. Freedom really peaked post world war as well and peaked during the cold war as well. Economy is really not talked about much until post World War and then comes up to be largest topic of the 2000s. Health spikes in the 1980s, coinciding with AIDS epidemic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155a072-02b3-4aa8-b9f1-e43a59e9a85d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 2 (5)\n",
    "\n",
    "![RIFF2](RIFF_2.png)\n",
    "This plot is hierarchial clustering of presidents based on average speech sentiment. The interesting pairing clustering include Donald Trump and Ronald Reagan being close together, which makes historical sense well as FDR and Lincoln being close together, having to rally the nation during turbulent times. With a few exception, the clustering ties very nicely with political party. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067c59b-8983-4acc-972a-1ecd852ded57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Riff 3 (5)\n",
    "\n",
    "![RIFF_3](RIFF_3.png)\n",
    "The final RIFF is t-SNE for speeches by topic. The visual shows that the topics are very closely tied with year in which you are president, with the darker colors being older presidents clustering together and the lighter colors being current presidents. This logically makes sense since presidential topics have changed overtime, and topics from one president to another usually do not change that much. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e25c6e-2624-4899-829e-e7d60c878685",
   "metadata": {},
   "source": [
    "# Interpretation (4)\n",
    "\n",
    "Describe something interesting about your corpus that you discovered during the process of completing this assignment.\n",
    "\n",
    "At a minumum, use 250 words, but you may use more. You may also add images if you'd like.\n",
    "\n",
    "The assignment was very interesting and rewarding, offering an excellent opportunity to apply what we learned in class and to a novel dataset. I focused on U.S. Presidential speeches, from George Washington to Donald Trump. The data was sourced from a CSV file on Kaggle, and I created tables to facilitate analysis.\n",
    "\n",
    "The first interesting point discovered from the corpus was in the PCA analysis, showing that Republicans among the parties have the most variation among their speeches. This finding was somewhat surprising, especially as the idea has only recently gained attention with the emergence of the MAGA movement. The loadings graph also provided fascinating insights, showing that while most speeches contained a common set of words, they diversified significantly, which makes sense given that many speeches share similar characteristics.\n",
    "\n",
    "Looking at sentiment, it was interesting to see trust have such a sharp decline over time and see how most of the sentiment followed the same ebbs and flows. These aligned with historical periods, with fear jumping during the depression and in 2000 post 9/11. Disgust and surprise did not show much overtime, which tracks as that sentiment shouldnâ€™t appear much in speeches by leaders.\n",
    "\n",
    "The three RIFFs brought in some interesting insights. Plotting key issues over time showed that they matched up with what was going on in the history of the country. The hierarchical clustering brought in some insights including presidents that had similar beliefs, including Reagan and Trump and presidents that faced similar challenges, like FDR and Lincoln. Finally, the plot of t-SNE topics showed that between each president, the topics did not change much but over the course of history they have changed a lot. \n",
    "\n",
    "Overall, the project uncovered many intriguing insights from the speeches, and most of the findings aligned with the historical interpretations of U.S. presidents.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
